{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In this question, we will determine the optimal learning rate for mini-batch gradient descent. Find the optimal learning rate for mini-batch gradient descent by training the neural network and evaluating the performances for different learning rates. Note: Use 5-fold cross-validation on the training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    ">Plot mean cross-validation accuracies on the final epoch for different learning rates as a scatter plot. Limit search space to learning rates {0.001, 0.005, 0.0001, 0.0005}. \n",
    "\n",
    ">Next, create a table of number of epochs required to reach convergence against different learning rates. \n",
    "\n",
    ">Finally, select the optimal learning rate and state a reason for your selection.\n",
    "\n",
    ">This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paste codes from Part A_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To reduce repeated code, place your\n",
    "> - network (MLP defined in QA1)\n",
    "> - torch datasets (CustomDataset defined in QA1)\n",
    "> - loss function (loss_fn defined in QA1)\n",
    "> in a separate file called common_utils.py\n",
    "\n",
    "> Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "> The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes that we will be importing are\n",
    "- `MLP` class: This class is robust and can handle any hyperparameters\n",
    "- `preprocess_dataset` method: Scaling of features is always a good practise\n",
    "- `initialize_loaders` method: We are still loading the same dataset by batches per epoch, and we can choose which subset of the dataset is used to create the loader.\n",
    "- `train_one_epoch` and `evaluate` methods: We are essentially doing Part A1 5 times (corresponding to 5 folds), and for each time we have a different training and testing dataset.\n",
    "\n",
    "What we are NOT importing\n",
    "- `preprocess` method that we created in A1: It does a train-test split which is not what we want to do in this case (we are doing cv folds here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import MLP, preprocess_dataset, intialise_loaders, train_one_epoch, evaluate\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "\n",
    "# Encode labels as integers\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Prepare training data and labels\n",
    "X_train: np.ndarray = df.drop(columns=['filename', 'label']).values\n",
    "y_train: np.ndarray = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define different folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Define different folds for different learning rates to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_learning_rates(\n",
    "        parameters  : list[int] ,   # List of learning rates to generate folds for\n",
    "        X_train     : np.ndarray, \n",
    "        y_train     : np.ndarray\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Generate cross-validation folds for each learning rate in the parameters list.\n",
    "    For each learning rate, we create 5 folds of the training data, preprocess them, \n",
    "    and store the scaled training and validation matrices along with their corresponding labels in dictionaries.\n",
    "\n",
    "    Args:\n",
    "        parameters(list[int]): A list of learning rates for which to generate cross-validation folds.\n",
    "        X_train(np.ndarray): The training data features.\n",
    "        y_train(np.ndarray): The training data labels.\n",
    "\n",
    "    Returns:\n",
    "        X_train_scaled_dict (dict): Keys are learning rates and values are lists of the preprocessed training matrices for the different folds.\n",
    "        X_val_scaled_dict (dict): Keys are learning rates and values are lists of the processed validation matrices for the different folds.\n",
    "        y_train_dict (dict): Keys are learning rates and values are lists of labels for the different folds\n",
    "        y_val_dict (dict): Keys are learning rates and values are lists of labels for the different folds\n",
    "    \"\"\"\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    X_train_scaled_dict : dict[int, list[np.ndarray]] = {}\n",
    "    X_val_scaled_dict   : dict[int, list[np.ndarray]] = {}\n",
    "    y_train_dict        : dict[int, list[np.ndarray]] = {}\n",
    "    y_val_dict          : dict[int, list[np.ndarray]] = {}\n",
    "\n",
    "    for learning_rate in parameters:\n",
    "\n",
    "        X_train_scaled_dict[learning_rate]  = []\n",
    "        X_val_scaled_dict[learning_rate]    = []\n",
    "        y_train_dict[learning_rate]         = []\n",
    "        y_val_dict[learning_rate]           = []\n",
    "\n",
    "        for train_indices, test_indices in kf.split(X_train):\n",
    "\n",
    "            X_train_fold, X_val_fold = X_train[train_indices], X_train[test_indices]\n",
    "            y_train_fold, y_val_fold = y_train[train_indices], y_train[test_indices]\n",
    "            \n",
    "            X_train_fold_scaled, X_test_fold_scaled = preprocess_dataset(X_train_fold, X_val_fold)\n",
    "            \n",
    "            # Store the scaled data and labels in the respective dictionaries\n",
    "            X_train_scaled_dict[learning_rate].append(X_train_fold_scaled)\n",
    "            X_val_scaled_dict[learning_rate].append(X_test_fold_scaled)\n",
    "            y_train_dict[learning_rate].append(y_train_fold)\n",
    "            y_val_dict[learning_rate].append(y_val_fold)\n",
    "\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "learning_rates = [0.001, 0.005, 0.0001, 0.0005]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_learning_rates(learning_rates, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Perform hyperparameter tuning for the different learning rates with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS          = 200\n",
    "NUM_FOLDS           = 5\n",
    "BATCH_SIZE          = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_hyperparameter(\n",
    "        X_train_scaled_dict : dict[int, list[np.ndarray]],\n",
    "        X_val_scaled_dict   : dict[int, list[np.ndarray]],\n",
    "        y_train_dict        : dict[int, list[np.ndarray]], \n",
    "        y_val_dict          : dict[int, list[np.ndarray]], \n",
    "        parameters          : list[int], \n",
    "        parameter_name      : str\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        cross_validation_accuracies(dict): Keys are learning rates and values are lists of the accuracies for the different folds.\n",
    "        cross_validation_times(dict): Keys are learning rates and values are lists of the times taken for the different folds.\n",
    "    \"\"\"\n",
    "    cross_validation_accuracies = {}\n",
    "    cross_validation_times = {}\n",
    "\n",
    "    print (f\"Finding optimal {parameter_name}...\")\n",
    "\n",
    "    for learning_rate in parameters:\n",
    "        print (f\"Evaluating {parameter_name} = {learning_rate}...\")\n",
    "\n",
    "        accuracies  = []    # List to store accuracies for each fold\n",
    "        times       = []    # List to store time taken for each fold\n",
    "\n",
    "        for fold in range (NUM_FOLDS):\n",
    "            print (f\"  Fold {fold+1}...\") # 2 space\n",
    "\n",
    "            X_train_scaled  = X_train_scaled_dict[learning_rate][fold]\n",
    "            X_val_scaled    = X_val_scaled_dict[learning_rate][fold]\n",
    "            y_train_fold    = y_train_dict[learning_rate][fold]\n",
    "            y_val_fold      = y_val_dict[learning_rate][fold]\n",
    "\n",
    "            train_data_loader, val_data_loader = intialise_loaders(\n",
    "                X_train_scaled  , \n",
    "                y_train_fold    , \n",
    "                X_val_scaled    , \n",
    "                y_val_fold      ,\n",
    "                batch_size      = BATCH_SIZE\n",
    "            )\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model = MLP(\n",
    "                num_features        = 77, \n",
    "                num_hidden_layers   = 3, \n",
    "                hidden_widths       = [128, 128, 128],\n",
    "                num_labels          = 1, \n",
    "                dropout             = 0.3\n",
    "            )\n",
    "\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr           = learning_rate,\n",
    "                weight_decay = 0.0005   \n",
    "            )\n",
    "\n",
    "            loss_fn = nn.BCELoss()\n",
    "\n",
    "            patience            = 5             # Number of epochs to wait for improvement in test loss before stopping training\n",
    "            max_val_accuracy    = 0.0           # Initialize best accuracy to 0 so that any improvement will be detected\n",
    "            patience_counter    = 0             # Counter to track how many epochs have passed without improvement in test loss\n",
    "            best_epoch          = 0             # To track the epoch at which the best model was saved\n",
    "            \n",
    "            # Evaluate the model with early stopping\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                train_loss, train_acc   = train_one_epoch(model, train_data_loader, loss_fn, optimizer)\n",
    "                val_loss, val_acc       = evaluate(model, val_data_loader, loss_fn)\n",
    "\n",
    "                # Print progress every 20 epochs\n",
    "                if (epoch + 1) % 20 == 0:\n",
    "                    print(f\"    Epoch [{epoch+1}/{NUM_EPOCHS}] - \" # 4 space\n",
    "                        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "                        f\"Test Loss: {val_loss:.4f}, Test Acc: {val_acc:.4f}\") \n",
    "\n",
    "                # Early stopping logic\n",
    "                # We use accuracy instead of loss as we only interested in best accuracy\n",
    "                if val_acc > max_val_accuracy:\n",
    "                    max_val_accuracy = val_acc\n",
    "                    patience_counter = 0\n",
    "                    best_epoch = epoch\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"    Early stopping at epoch {epoch+1} for learning rate {learning_rate}\") # 4 space\n",
    "                    break\n",
    "\n",
    "            print (f\"    Best validation accuracy for learning rate {learning_rate} in fold {fold+1}: {max_val_accuracy:.4f} at epoch {best_epoch+1}\") # 4 space\n",
    "\n",
    "            accuracies.append(max_val_accuracy)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            fold_time = end_time - start_time\n",
    "            times.append(fold_time)\n",
    "\n",
    "        cross_validation_accuracies[learning_rate] = accuracies\n",
    "        cross_validation_times[learning_rate] = times\n",
    "\n",
    "    return cross_validation_accuracies, cross_validation_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding optimal learning_rate...\n",
      "Evaluating learning_rate = 0.001...\n",
      "  Fold 1...\n",
      "    Epoch [20/200] - Train Loss: 0.4838, Train Acc: 0.7683 | Test Loss: 0.5583, Test Acc: 0.7106\n",
      "    Early stopping at epoch 27 for learning rate 0.001\n",
      "    Best validation accuracy for learning rate 0.001 in fold 1: 0.7488 at epoch 22\n",
      "  Fold 2...\n",
      "    Epoch [20/200] - Train Loss: 0.4893, Train Acc: 0.7571 | Test Loss: 0.5382, Test Acc: 0.7181\n",
      "    Epoch [40/200] - Train Loss: 0.3960, Train Acc: 0.8234 | Test Loss: 0.5030, Test Acc: 0.7604\n",
      "    Early stopping at epoch 41 for learning rate 0.001\n",
      "    Best validation accuracy for learning rate 0.001 in fold 2: 0.7649 at epoch 36\n",
      "  Fold 3...\n",
      "    Epoch [20/200] - Train Loss: 0.4974, Train Acc: 0.7582 | Test Loss: 0.5308, Test Acc: 0.7312\n",
      "    Early stopping at epoch 22 for learning rate 0.001\n",
      "    Best validation accuracy for learning rate 0.001 in fold 3: 0.7341 at epoch 17\n",
      "  Fold 4...\n",
      "    Epoch [20/200] - Train Loss: 0.4906, Train Acc: 0.7527 | Test Loss: 0.5368, Test Acc: 0.7258\n",
      "    Early stopping at epoch 30 for learning rate 0.001\n",
      "    Best validation accuracy for learning rate 0.001 in fold 4: 0.7561 at epoch 25\n",
      "  Fold 5...\n",
      "    Epoch [20/200] - Train Loss: 0.5013, Train Acc: 0.7517 | Test Loss: 0.5413, Test Acc: 0.7200\n",
      "    Epoch [40/200] - Train Loss: 0.3967, Train Acc: 0.8191 | Test Loss: 0.4890, Test Acc: 0.7623\n",
      "    Early stopping at epoch 59 for learning rate 0.001\n",
      "    Best validation accuracy for learning rate 0.001 in fold 5: 0.7756 at epoch 54\n",
      "Evaluating learning_rate = 0.005...\n",
      "  Fold 1...\n",
      "    Epoch [20/200] - Train Loss: 0.6126, Train Acc: 0.6501 | Test Loss: 0.6055, Test Acc: 0.6621\n",
      "    Early stopping at epoch 30 for learning rate 0.005\n",
      "    Best validation accuracy for learning rate 0.005 in fold 1: 0.6841 at epoch 25\n",
      "  Fold 2...\n",
      "    Early stopping at epoch 14 for learning rate 0.005\n",
      "    Best validation accuracy for learning rate 0.005 in fold 2: 0.6352 at epoch 9\n",
      "  Fold 3...\n",
      "    Epoch [20/200] - Train Loss: 0.6099, Train Acc: 0.6458 | Test Loss: 0.6316, Test Acc: 0.6408\n",
      "    Epoch [40/200] - Train Loss: 0.5658, Train Acc: 0.6933 | Test Loss: 0.5849, Test Acc: 0.6674\n",
      "    Early stopping at epoch 40 for learning rate 0.005\n",
      "    Best validation accuracy for learning rate 0.005 in fold 3: 0.6860 at epoch 35\n",
      "  Fold 4...\n",
      "    Epoch [20/200] - Train Loss: 0.6141, Train Acc: 0.6527 | Test Loss: 0.6237, Test Acc: 0.6425\n",
      "    Epoch [40/200] - Train Loss: 0.5764, Train Acc: 0.6825 | Test Loss: 0.5903, Test Acc: 0.6719\n",
      "    Early stopping at epoch 41 for learning rate 0.005\n",
      "    Best validation accuracy for learning rate 0.005 in fold 4: 0.6719 at epoch 36\n",
      "  Fold 5...\n",
      "    Early stopping at epoch 16 for learning rate 0.005\n",
      "    Best validation accuracy for learning rate 0.005 in fold 5: 0.6367 at epoch 11\n",
      "Evaluating learning_rate = 0.0001...\n",
      "  Fold 1...\n",
      "    Epoch [20/200] - Train Loss: 0.6313, Train Acc: 0.6425 | Test Loss: 0.6281, Test Acc: 0.6410\n",
      "    Epoch [40/200] - Train Loss: 0.5840, Train Acc: 0.6874 | Test Loss: 0.5968, Test Acc: 0.6874\n",
      "    Epoch [60/200] - Train Loss: 0.5400, Train Acc: 0.7262 | Test Loss: 0.5643, Test Acc: 0.7110\n",
      "    Epoch [80/200] - Train Loss: 0.4978, Train Acc: 0.7567 | Test Loss: 0.5389, Test Acc: 0.7280\n",
      "    Early stopping at epoch 81 for learning rate 0.0001\n",
      "    Best validation accuracy for learning rate 0.0001 in fold 1: 0.7338 at epoch 76\n",
      "  Fold 2...\n",
      "    Epoch [20/200] - Train Loss: 0.6314, Train Acc: 0.6422 | Test Loss: 0.6275, Test Acc: 0.6522\n",
      "    Epoch [40/200] - Train Loss: 0.5844, Train Acc: 0.6878 | Test Loss: 0.5902, Test Acc: 0.6857\n",
      "    Early stopping at epoch 56 for learning rate 0.0001\n",
      "    Best validation accuracy for learning rate 0.0001 in fold 2: 0.7119 at epoch 51\n",
      "  Fold 3...\n",
      "    Epoch [20/200] - Train Loss: 0.6310, Train Acc: 0.6442 | Test Loss: 0.6350, Test Acc: 0.6371\n",
      "    Epoch [40/200] - Train Loss: 0.5855, Train Acc: 0.6902 | Test Loss: 0.5963, Test Acc: 0.6786\n",
      "    Epoch [60/200] - Train Loss: 0.5467, Train Acc: 0.7152 | Test Loss: 0.5663, Test Acc: 0.7063\n",
      "    Epoch [80/200] - Train Loss: 0.5051, Train Acc: 0.7511 | Test Loss: 0.5393, Test Acc: 0.7196\n",
      "    Early stopping at epoch 97 for learning rate 0.0001\n",
      "    Best validation accuracy for learning rate 0.0001 in fold 3: 0.7399 at epoch 92\n",
      "  Fold 4...\n",
      "    Epoch [20/200] - Train Loss: 0.6301, Train Acc: 0.6401 | Test Loss: 0.6450, Test Acc: 0.6201\n",
      "    Epoch [40/200] - Train Loss: 0.5859, Train Acc: 0.6870 | Test Loss: 0.6150, Test Acc: 0.6566\n",
      "    Early stopping at epoch 48 for learning rate 0.0001\n",
      "    Best validation accuracy for learning rate 0.0001 in fold 4: 0.6669 at epoch 43\n",
      "  Fold 5...\n",
      "    Epoch [20/200] - Train Loss: 0.6283, Train Acc: 0.6441 | Test Loss: 0.6481, Test Acc: 0.6201\n",
      "    Epoch [40/200] - Train Loss: 0.5836, Train Acc: 0.6874 | Test Loss: 0.6116, Test Acc: 0.6703\n",
      "    Epoch [60/200] - Train Loss: 0.5462, Train Acc: 0.7194 | Test Loss: 0.5790, Test Acc: 0.7039\n",
      "    Epoch [80/200] - Train Loss: 0.5064, Train Acc: 0.7495 | Test Loss: 0.5483, Test Acc: 0.7337\n",
      "    Early stopping at epoch 95 for learning rate 0.0001\n",
      "    Best validation accuracy for learning rate 0.0001 in fold 5: 0.7491 at epoch 90\n",
      "Evaluating learning_rate = 0.0005...\n",
      "  Fold 1...\n",
      "    Epoch [20/200] - Train Loss: 0.5125, Train Acc: 0.7429 | Test Loss: 0.5390, Test Acc: 0.7334\n",
      "    Epoch [40/200] - Train Loss: 0.4144, Train Acc: 0.8083 | Test Loss: 0.5027, Test Acc: 0.7703\n",
      "    Early stopping at epoch 45 for learning rate 0.0005\n",
      "    Best validation accuracy for learning rate 0.0005 in fold 1: 0.7703 at epoch 40\n",
      "  Fold 2...\n",
      "    Epoch [20/200] - Train Loss: 0.5181, Train Acc: 0.7410 | Test Loss: 0.5374, Test Acc: 0.7218\n",
      "    Epoch [40/200] - Train Loss: 0.4072, Train Acc: 0.8143 | Test Loss: 0.4931, Test Acc: 0.7691\n",
      "    Early stopping at epoch 46 for learning rate 0.0005\n",
      "    Best validation accuracy for learning rate 0.0005 in fold 2: 0.7716 at epoch 41\n",
      "  Fold 3...\n",
      "    Epoch [20/200] - Train Loss: 0.5244, Train Acc: 0.7329 | Test Loss: 0.5493, Test Acc: 0.7163\n",
      "    Epoch [40/200] - Train Loss: 0.4183, Train Acc: 0.8020 | Test Loss: 0.4902, Test Acc: 0.7657\n",
      "    Early stopping at epoch 42 for learning rate 0.0005\n",
      "    Best validation accuracy for learning rate 0.0005 in fold 3: 0.7686 at epoch 37\n",
      "  Fold 4...\n",
      "    Epoch [20/200] - Train Loss: 0.5270, Train Acc: 0.7328 | Test Loss: 0.5618, Test Acc: 0.6993\n",
      "    Epoch [40/200] - Train Loss: 0.4289, Train Acc: 0.7997 | Test Loss: 0.4940, Test Acc: 0.7582\n",
      "    Early stopping at epoch 40 for learning rate 0.0005\n",
      "    Best validation accuracy for learning rate 0.0005 in fold 4: 0.7644 at epoch 35\n",
      "  Fold 5...\n",
      "    Epoch [20/200] - Train Loss: 0.5182, Train Acc: 0.7394 | Test Loss: 0.5537, Test Acc: 0.7138\n",
      "    Epoch [40/200] - Train Loss: 0.4167, Train Acc: 0.8067 | Test Loss: 0.4893, Test Acc: 0.7648\n",
      "    Early stopping at epoch 41 for learning rate 0.0005\n",
      "    Best validation accuracy for learning rate 0.0005 in fold 5: 0.7677 at epoch 36\n"
     ]
    }
   ],
   "source": [
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(\n",
    "    X_train_scaled_dict, \n",
    "    X_val_scaled_dict, \n",
    "    y_train_dict, \n",
    "    y_val_dict, \n",
    "    learning_rates, \n",
    "    'learning_rate'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visulization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot scatterplot of mean cross validation accuracies for the different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Accuracies:\n",
      "Learning Rate 0.0001: 0.7203\n",
      "Learning Rate 0.0005: 0.7685\n",
      "Learning Rate 0.001: 0.7559\n",
      "Learning Rate 0.005: 0.6628\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean cross-validation accuracies for each learning rate\n",
    "mean_accuracies = {learning_rate: np.mean(accuracies) for learning_rate, accuracies in cross_validation_accuracies.items()}\n",
    "\n",
    "# Sort for cleaner plotting\n",
    "x_vals = sorted(mean_accuracies.keys())\n",
    "y_vals = [mean_accuracies[lr] for lr in x_vals]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_vals, y_vals, s=100, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Mean Cross-Validation Accuracy')\n",
    "plt.title('Mean Cross-Validation Accuracies vs Learning Rates')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "\n",
    "# Force one tick label per learning-rate point\n",
    "plt.xticks(x_vals, [f\"{lr:.4g}\" for lr in x_vals])\n",
    "\n",
    "# Add value labels on each point\n",
    "for lr, acc in zip(x_vals, y_vals):\n",
    "    plt.annotate(f'{acc:.4f}', (lr, acc), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Cross-Validation Accuracies:\")\n",
    "for lr, acc in zip(x_vals, y_vals):\n",
    "    print(f\"Learning Rate {lr}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimal Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table of number of epochs required to reach convergence against different learning rates. Select the optimal learning rate and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Mean Time (seconds)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>2.562198</td>\n",
       "      <td>0.755909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>2.001662</td>\n",
       "      <td>0.662769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>5.424999</td>\n",
       "      <td>0.720328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>2.973104</td>\n",
       "      <td>0.768516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Mean Time (seconds)  Accuracy\n",
       "0         0.0010             2.562198  0.755909\n",
       "1         0.0050             2.001662  0.662769\n",
       "2         0.0001             5.424999  0.720328\n",
       "3         0.0005             2.973104  0.768516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_times = {learning_rate: np.mean(times) for learning_rate, times in cross_validation_times.items()}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Learning Rate'         : list(mean_times.keys()),\n",
    "    'Mean Time (seconds)'   : list(mean_times.values()),\n",
    "    'Accuracy'              : list(mean_accuracies.values())\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal Learning Rate = 0.0005**\n",
    "\n",
    "It resulted in the highest accuracy among all 4 learning rates. On the other hand, learning rate of 0.0010 sacrifised accuracy slightly with faster mean time to convergence. While the difference in time is insignificant here, if the dataset happens to be very large, learning rate of 0.00010 can be considered as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
